p8105_hw3_md4270
================
Manye Dong
2023-10-07

``` r
library(tidyverse)
```

## Problem 1

``` r
library(p8105.datasets)
data("instacart")
```

The `instacart` dataset has 1384617 number of rows and 15 number of
columns. Each row is an order placed. Key variables contain the order
id, product id, user id, the order date, product id and the aisle it’s
in.

``` r
aisle_num = length(unique(instacart$aisle_id))
```

``` r
aisle_most = instacart |>
  group_by(aisle) |>
  summarise(num_products = n()) |>
  arrange(desc(num_products))

aisle_most
```

    ## # A tibble: 134 × 2
    ##    aisle                         num_products
    ##    <chr>                                <int>
    ##  1 fresh vegetables                    150609
    ##  2 fresh fruits                        150473
    ##  3 packaged vegetables fruits           78493
    ##  4 yogurt                               55240
    ##  5 packaged cheese                      41699
    ##  6 water seltzer sparkling water        36617
    ##  7 milk                                 32644
    ##  8 chips pretzels                       31269
    ##  9 soy lactosefree                      26240
    ## 10 bread                                23635
    ## # ℹ 124 more rows

- There are 134 number of aisles, and fresh vegetables is the aisle
  where most items are ordered from.

Make a plot that shows the number of items ordered in each aisle,
limiting this to aisles with more than 10000 items ordered. Arrange
aisles sensibly, and organize your plot so others can read it.

``` r
instacart |>
  group_by(aisle) |>
  summarize(items_num = n()) |>
  filter(items_num > 10000) |>
  arrange(desc(items_num)) |>
  ggplot(aes(x=aisle, y=items_num)) +
  geom_bar(stat="identity", fill = "skyblue", color = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Aisle", y = "Number of Items", title = "Items in 39 Aisles")
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
Include the number of times each item is ordered in your table.

``` r
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable(title = "Top 3 Most Popular Items in Selected Aisles", 
               col.names = c("Aisle", "Product Name", "Numbers Sold", "Rank"))
```

| Aisle                      | Product Name                                  | Numbers Sold | Rank |
|:---------------------------|:----------------------------------------------|-------------:|-----:|
| packaged vegetables fruits | Organic Baby Spinach                          |         9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           |         5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           |         4966 |    3 |
| baking ingredients         | Light Brown Sugar                             |          499 |    1 |
| baking ingredients         | Pure Baking Soda                              |          387 |    2 |
| baking ingredients         | Cane Sugar                                    |          336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |           30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |           28 |    2 |
| dog food care              | Small Dog Biscuits                            |           26 |    3 |

Make a table showing the mean hour of the day at which Pink Lady Apples
and Coffee Ice Cream are ordered on each day of the week; format this
table for human readers (i.e. produce a 2 x 7 table).

``` r
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2)
```

| product_name     |     0 |     1 |     2 |     3 |     4 |     5 |     6 |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

## Problem 2

``` r
library(p8105.datasets)
data("brfss_smart2010")
```

``` r
head(brfss_smart2010)
```

    ## # A tibble: 6 × 23
    ##    Year Locationabbr Locationdesc      Class Topic Question Response Sample_Size
    ##   <int> <chr>        <chr>             <chr> <chr> <chr>    <chr>          <int>
    ## 1  2010 AL           AL - Jefferson C… Heal… Over… How is … Excelle…          94
    ## 2  2010 AL           AL - Jefferson C… Heal… Over… How is … Very go…         148
    ## 3  2010 AL           AL - Jefferson C… Heal… Over… How is … Good             208
    ## 4  2010 AL           AL - Jefferson C… Heal… Over… How is … Fair             107
    ## 5  2010 AL           AL - Jefferson C… Heal… Over… How is … Poor              45
    ## 6  2010 AL           AL - Jefferson C… Heal… Fair… Health … Good or…         450
    ## # ℹ 15 more variables: Data_value <dbl>, Confidence_limit_Low <dbl>,
    ## #   Confidence_limit_High <dbl>, Display_order <int>, Data_value_unit <chr>,
    ## #   Data_value_type <chr>, Data_Value_Footnote_Symbol <chr>,
    ## #   Data_Value_Footnote <chr>, DataSource <chr>, ClassId <chr>, TopicId <chr>,
    ## #   LocationID <chr>, QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

Clean the data based on instructions:

``` r
brfss_smart2010_cleaned = 
  brfss_smart2010 |>
  janitor::clean_names() |>
  rename("state"="locationabbr", "county"="locationdesc") |> 
  filter(topic=="Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor"))
  
brfss_smart2010_cleaned$response = 
  factor(brfss_smart2010_cleaned$response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), ordered = TRUE)
  
head(brfss_smart2010_cleaned)
```

    ## # A tibble: 6 × 23
    ##    year state county        class topic question response sample_size data_value
    ##   <int> <chr> <chr>         <chr> <chr> <chr>    <ord>          <int>      <dbl>
    ## 1  2010 AL    AL - Jeffers… Heal… Over… How is … Excelle…          94       18.9
    ## 2  2010 AL    AL - Jeffers… Heal… Over… How is … Very go…         148       30  
    ## 3  2010 AL    AL - Jeffers… Heal… Over… How is … Good             208       33.1
    ## 4  2010 AL    AL - Jeffers… Heal… Over… How is … Fair             107       12.5
    ## 5  2010 AL    AL - Jeffers… Heal… Over… How is … Poor              45        5.5
    ## 6  2010 AL    AL - Mobile … Heal… Over… How is … Excelle…          91       15.6
    ## # ℹ 14 more variables: confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

``` r
locations_2002 = 
  brfss_smart2010_cleaned |>
  filter(year==2002) |>
  group_by(state) |>
  summarize(num_location = n_distinct(county)) |>
  filter(num_location >= 7)

head(locations_2002)
```

    ## # A tibble: 6 × 2
    ##   state num_location
    ##   <chr>        <int>
    ## 1 CT               7
    ## 2 FL               7
    ## 3 MA               8
    ## 4 NC               7
    ## 5 NJ               8
    ## 6 PA              10

In 2002, states CT, FL, MA, NC, NJ, PA were observed at 7 or more
locations.

``` r
locations_2010 = 
  brfss_smart2010_cleaned |>
  filter(year==2010) |>
  group_by(state) |>
  summarize(num_location = n_distinct(county)) |>
  filter(num_location >= 7)

head(locations_2010)
```

    ## # A tibble: 6 × 2
    ##   state num_location
    ##   <chr>        <int>
    ## 1 CA              12
    ## 2 CO               7
    ## 3 FL              41
    ## 4 MA               9
    ## 5 MD              12
    ## 6 NC              12

In 2010, states CT, FL, MA, NC, NJ, PA were observed at 7 or more
locations.

Construct a dataset that is limited to Excellent responses, and
contains, year, state, and a variable that averages the data_value
across locations within a state:

``` r
avg_values = 
brfss_smart2010_cleaned |>
  filter(response=="Excellent") |>
  select(-county) |>
  group_by(year, state) |>
  mutate(avg_data_value = mean(data_value, na.rm = TRUE)) |>
  select(year, state, avg_data_value)
  
avg_values
```

    ## # A tibble: 2,125 × 3
    ## # Groups:   year, state [443]
    ##     year state avg_data_value
    ##    <int> <chr>          <dbl>
    ##  1  2010 AL              18.4
    ##  2  2010 AL              18.4
    ##  3  2010 AL              18.4
    ##  4  2010 AZ              21.6
    ##  5  2010 AZ              21.6
    ##  6  2010 AZ              21.6
    ##  7  2010 AR              25.4
    ##  8  2010 AR              25.4
    ##  9  2010 AR              25.4
    ## 10  2010 CA              23.9
    ## # ℹ 2,115 more rows

Make a “spaghetti” plot of this average value over time within a state
(that is, make a plot showing a line for each state across years – the
geom_line geometry and group aesthetic will help).

``` r
ggplot(avg_values, aes(x = year, y = avg_data_value, color = state, group = state)) +
  geom_line() +
  labs(x = "Year", y = "Average Value", title = "Spaghetti Plot of Average Values Over Time by State") +
  theme_minimal()
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

Make a two-panel plot showing, for the years 2006, and 2010,
distribution of data_value for responses (“Poor” to “Excellent”) among
locations in NY State:

``` r
ny_data = brfss_smart2010_cleaned |>
filter(brfss_smart2010_cleaned$state == "NY" 
       & brfss_smart2010_cleaned$year %in% c(2006, 2010))
```

``` r
ggplot(ny_data, aes(x = response, y = data_value, fill = response)) +
  geom_boxplot() +
  facet_wrap(~year, scales = "free_y") +
  labs(title = "Distribution of data_value for Responses in NY State",
       y = "Data Value",
       x = "Response") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->

## Problem 3

Clean the data according to instructions:

``` r
library(readr)
nhanes_accel = read_csv("nhanes_accel.csv")
nhanes_covar = read_csv("nhanes_covar.csv", skip = 4)
```

``` r
nhanes_accel_cleaned = 
  nhanes_accel |>
  janitor::clean_names()
```

``` r
nhanes_covar_cleaned =
  nhanes_covar |>
  janitor::clean_names() |>
  mutate(
      sex = recode(sex, "1" = "male", "2" = "female"),
      education = recode(education, "1" = "Less than high school", 
                         "2" = "High school equivalent", 
                         "3" = "More than high school")) |>
  mutate(sex = factor(sex), 
         education = factor(education)) |>
  filter(age >= 21) |>
  drop_na()

nhanes_covar_cleaned
```

    ## # A tibble: 228 × 5
    ##     seqn sex      age   bmi education             
    ##    <dbl> <fct>  <dbl> <dbl> <fct>                 
    ##  1 62161 male      22  23.3 High school equivalent
    ##  2 62164 female    44  23.2 More than high school 
    ##  3 62169 male      21  20.1 High school equivalent
    ##  4 62174 male      80  33.9 More than high school 
    ##  5 62177 male      51  20.1 High school equivalent
    ##  6 62178 male      80  28.5 High school equivalent
    ##  7 62180 male      35  27.9 More than high school 
    ##  8 62184 male      26  22.1 High school equivalent
    ##  9 62189 female    30  22.4 More than high school 
    ## 10 62199 male      57  28   More than high school 
    ## # ℹ 218 more rows

Now, we join the two cleaned tables to include all valid observations:

``` r
nhanes = merge(nhanes_covar_cleaned, nhanes_accel_cleaned, by = "seqn")
```

Produce a reader-friendly table for the number of men and women in each
education category:

``` r
nhanes_sex_tbl = 
  nhanes |>
  group_by(education, sex) |>
  summarize(num_people = n_distinct(seqn))|>
  pivot_wider(names_from = sex, values_from = num_people) |>
  arrange(education) |>
  knitr::kable(title = "Number of Men and Women in Each Education Category", 
               col.names = c("Education", "Female", "Male"))

nhanes_sex_tbl
```

| Education              | Female | Male |
|:-----------------------|-------:|-----:|
| High school equivalent |     23 |   35 |
| Less than high school  |     28 |   27 |
| More than high school  |     59 |   56 |

Next, create a visualization of the age distributions for men and women
in each education category:

``` r
ggplot(nhanes, aes(x = education, y = age, fill = sex)) +
  geom_boxplot() +
  labs(title = "Age Distribution by Gender and Education",
       x = "Education Level",
       y = "Age") +
  theme_minimal()
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-22-1.png)<!-- -->

“There are more female in the higher education group, more male have a
high school equivalent background. This box-plot shows the age
distribution of men and women in three different education levels. As a
result, younger people appear to have a higher education level (more
than high school), the middle age group have relevant lower education.”

Using your tidied dataset, aggregate across minutes to create a total
activity variable for each participant:

``` r
total_act = nhanes |>
  mutate(total_activity = rowSums(across(min1:min1440), na.rm = TRUE))
```

Make a 3-panel plot:

``` r
ggplot(total_act, aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = .5) +
  facet_wrap(~education) +
  geom_smooth() +
  labs(title = "Total Activity for Male vs Female", 
       x = "Age", 
       y = "Total Activity")
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-24-1.png)<!-- -->

Comment on your plot:

Lastly, we make a 24-hour activity time courses plot:

``` r
total_act_24hrs = 
  nhanes |>
  group_by(education, sex) |>
  summarise(across(starts_with("min"), ~ mean(.), .names = "mean_{.col}")) |>
  pivot_longer(
    cols = starts_with("mean_"), 
    names_to = "time", 
    values_to = "mean") |>
  mutate(time = substring(time, 9),
         time = as.numeric(time))
```

Make a 3-panel plot:

``` r
ggplot(total_act_24hrs, aes(x = time, y = mean, color = sex)) +
  geom_line() +
  facet_grid(. ~education) +
  labs(title = "24-Hour Activity by Education and Gender", 
       x = "Time (min)", 
       y = "Activity")
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-26-1.png)<!-- -->

Comment on plots:

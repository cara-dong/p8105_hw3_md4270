p8105_hw3_md4270
================
Manye Dong
2023-10-07

``` r
library(tidyverse)
```

## Problem 1

``` r
library(p8105.datasets)
data("instacart")
```

The `instacart` dataset has 1384617 number of rows and 15 number of
columns. Each row is a single product from an instacart order placed.
Key variables contain the order id, product id, user id, the order date,
product id and the aisle it’s in.

In total, there are 39123 products found in 131209 orders from 131209
distinct users.

``` r
aisle_num = length(unique(instacart$aisle_id))
```

``` r
aisle_most = instacart |>
  group_by(aisle) |>
  summarise(num_products = n()) |>
  arrange(desc(num_products))

aisle_most
```

    ## # A tibble: 134 × 2
    ##    aisle                         num_products
    ##    <chr>                                <int>
    ##  1 fresh vegetables                    150609
    ##  2 fresh fruits                        150473
    ##  3 packaged vegetables fruits           78493
    ##  4 yogurt                               55240
    ##  5 packaged cheese                      41699
    ##  6 water seltzer sparkling water        36617
    ##  7 milk                                 32644
    ##  8 chips pretzels                       31269
    ##  9 soy lactosefree                      26240
    ## 10 bread                                23635
    ## # ℹ 124 more rows

- There are 134 number of aisles, and fresh vegetables is the aisle
  where most items are ordered from.

Make a plot that shows the number of items ordered in each aisle,
limiting this to aisles with more than 10000 items ordered. Arrange
aisles sensibly, and organize your plot so others can read it.

``` r
instacart |> 
  count(aisle) |> 
  filter(n > 10000) |> 
  mutate(aisle = fct_reorder(aisle, n)) |> 
  ggplot(aes(x = aisle, y = n)) + 
  geom_bar(stat="identity", fill = "skyblue", color = "black") +
  labs(title = "Number of Items Ordered In Each Aisle", 
       x = "Aisle", 
       y = "Number of Items") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
Include the number of times each item is ordered in your table.

``` r
instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable(title = "Top 3 Most Popular Items in Selected Aisles", 
               col.names = c("Aisle", "Product Name", "Numbers Sold", "Rank"))
```

| Aisle                      | Product Name                                  | Numbers Sold | Rank |
|:---------------------------|:----------------------------------------------|-------------:|-----:|
| packaged vegetables fruits | Organic Baby Spinach                          |         9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           |         5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           |         4966 |    3 |
| baking ingredients         | Light Brown Sugar                             |          499 |    1 |
| baking ingredients         | Pure Baking Soda                              |          387 |    2 |
| baking ingredients         | Cane Sugar                                    |          336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |           30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |           28 |    2 |
| dog food care              | Small Dog Biscuits                            |           26 |    3 |

Make a table showing the mean hour of the day at which Pink Lady Apples
and Coffee Ice Cream are ordered on each day of the week; format this
table for human readers (i.e. produce a 2 x 7 table).

``` r
instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable(digits = 2, 
               col.names = c("Product Name", "Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"))
```

| Product Name     |   Sun |   Mon |   Tue |   Wed |   Thu |   Fri |   Sat |
|:-----------------|------:|------:|------:|------:|------:|------:|------:|
| Coffee Ice Cream | 13.77 | 14.32 | 15.38 | 15.32 | 15.22 | 12.26 | 13.83 |
| Pink Lady Apples | 13.44 | 11.36 | 11.70 | 14.25 | 11.55 | 12.78 | 11.94 |

## Problem 2

``` r
library(p8105.datasets)
data("brfss_smart2010")
```

``` r
head(brfss_smart2010)
```

    ## # A tibble: 6 × 23
    ##    Year Locationabbr Locationdesc      Class Topic Question Response Sample_Size
    ##   <int> <chr>        <chr>             <chr> <chr> <chr>    <chr>          <int>
    ## 1  2010 AL           AL - Jefferson C… Heal… Over… How is … Excelle…          94
    ## 2  2010 AL           AL - Jefferson C… Heal… Over… How is … Very go…         148
    ## 3  2010 AL           AL - Jefferson C… Heal… Over… How is … Good             208
    ## 4  2010 AL           AL - Jefferson C… Heal… Over… How is … Fair             107
    ## 5  2010 AL           AL - Jefferson C… Heal… Over… How is … Poor              45
    ## 6  2010 AL           AL - Jefferson C… Heal… Fair… Health … Good or…         450
    ## # ℹ 15 more variables: Data_value <dbl>, Confidence_limit_Low <dbl>,
    ## #   Confidence_limit_High <dbl>, Display_order <int>, Data_value_unit <chr>,
    ## #   Data_value_type <chr>, Data_Value_Footnote_Symbol <chr>,
    ## #   Data_Value_Footnote <chr>, DataSource <chr>, ClassId <chr>, TopicId <chr>,
    ## #   LocationID <chr>, QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

Clean the data based on instructions:

``` r
brfss_smart2010_cleaned = 
  brfss_smart2010 |>
  janitor::clean_names() |>
  rename("state"="locationabbr", "county"="locationdesc") |> 
  filter(topic=="Overall Health" & response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) |>
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent")))
  
head(brfss_smart2010_cleaned)
```

    ## # A tibble: 6 × 23
    ##    year state county        class topic question response sample_size data_value
    ##   <int> <chr> <chr>         <chr> <chr> <chr>    <fct>          <int>      <dbl>
    ## 1  2010 AL    AL - Jeffers… Heal… Over… How is … Excelle…          94       18.9
    ## 2  2010 AL    AL - Jeffers… Heal… Over… How is … Very go…         148       30  
    ## 3  2010 AL    AL - Jeffers… Heal… Over… How is … Good             208       33.1
    ## 4  2010 AL    AL - Jeffers… Heal… Over… How is … Fair             107       12.5
    ## 5  2010 AL    AL - Jeffers… Heal… Over… How is … Poor              45        5.5
    ## 6  2010 AL    AL - Mobile … Heal… Over… How is … Excelle…          91       15.6
    ## # ℹ 14 more variables: confidence_limit_low <dbl>, confidence_limit_high <dbl>,
    ## #   display_order <int>, data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

``` r
locations_2002 = 
  brfss_smart2010_cleaned |>
  filter(year==2002) |>
  group_by(year, state) |>
  summarize(num_location = n_distinct(county)) |>
  filter(num_location >= 7)
```

In 2002, states CT, FL, MA, NC, NJ, PA were observed at 7 or more
locations.

``` r
locations_2010 = 
  brfss_smart2010_cleaned |>
  filter(year==2010) |>
  group_by(year, state) |>
  summarize(num_location = n_distinct(county)) |>
  filter(num_location >= 7)
```

    ## `summarise()` has grouped output by 'year'. You can override using the
    ## `.groups` argument.

In 2010, states CT, FL, MA, NC, NJ, PA were observed at 7 or more
locations.

Construct a dataset that is limited to Excellent responses, and
contains, year, state, and a variable that averages the data_value
across locations within a state:

``` r
avg_values = 
brfss_smart2010_cleaned |>
  filter(response=="Excellent") |>
  select(-county) |>
  group_by(year, state) |>
  mutate(avg_data_value = mean(data_value, na.rm = TRUE)) |>
  select(year, state, avg_data_value)
  
avg_values
```

    ## # A tibble: 2,125 × 3
    ## # Groups:   year, state [443]
    ##     year state avg_data_value
    ##    <int> <chr>          <dbl>
    ##  1  2010 AL              18.4
    ##  2  2010 AL              18.4
    ##  3  2010 AL              18.4
    ##  4  2010 AZ              21.6
    ##  5  2010 AZ              21.6
    ##  6  2010 AZ              21.6
    ##  7  2010 AR              25.4
    ##  8  2010 AR              25.4
    ##  9  2010 AR              25.4
    ## 10  2010 CA              23.9
    ## # ℹ 2,115 more rows

Make a “spaghetti” plot of this average value over time within a state
(that is, make a plot showing a line for each state across years – the
geom_line geometry and group aesthetic will help).

``` r
ggplot(avg_values, aes(x = year, y = avg_data_value, color = state, group = state)) +
  geom_line() +
  labs(x = "Year", y = "Average Value", title = "Spaghetti Plot of Average Values Over Time by State") +
  theme_minimal()
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-14-1.png)<!-- -->

Make a two-panel plot showing, for the years 2006, and 2010,
distribution of data_value for responses (“Poor” to “Excellent”) among
locations in NY State:

``` r
ny_data = brfss_smart2010_cleaned |>
filter(brfss_smart2010_cleaned$state == "NY" 
       & brfss_smart2010_cleaned$year %in% c(2006, 2010))
```

``` r
ggplot(ny_data, aes(x = response, y = data_value, fill = response)) +
  geom_boxplot() +
  facet_wrap(~year, scales = "free_y") +
  scale_fill_brewer(palette = "Pastel1", name = "Response") +
  labs(title = "Distribution of Data Value for Responses in NY State",
       y = "Data Value",
       x = "Response") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-16-1.png)<!-- -->

## Problem 3

Clean the data according to instructions:

``` r
library(readr)
nhanes_accel = read_csv("nhanes_accel.csv")
nhanes_covar = read_csv("nhanes_covar.csv", skip = 4)
```

``` r
nhanes_accel_cleaned = 
  nhanes_accel |>
  janitor::clean_names()
```

``` r
nhanes_covar_cleaned =
  nhanes_covar |>
  janitor::clean_names() |>
  mutate(
      sex = recode(sex, "1" = "male", "2" = "female"),
      education = recode(education, "1" = "Less than high school", 
                         "2" = "High school equivalent", 
                         "3" = "More than high school")) |>
  mutate(sex = factor(sex), 
         education = factor(education)) |>
  filter(age >= 21) |>
  drop_na()

nhanes_covar_cleaned
```

    ## # A tibble: 228 × 5
    ##     seqn sex      age   bmi education             
    ##    <dbl> <fct>  <dbl> <dbl> <fct>                 
    ##  1 62161 male      22  23.3 High school equivalent
    ##  2 62164 female    44  23.2 More than high school 
    ##  3 62169 male      21  20.1 High school equivalent
    ##  4 62174 male      80  33.9 More than high school 
    ##  5 62177 male      51  20.1 High school equivalent
    ##  6 62178 male      80  28.5 High school equivalent
    ##  7 62180 male      35  27.9 More than high school 
    ##  8 62184 male      26  22.1 High school equivalent
    ##  9 62189 female    30  22.4 More than high school 
    ## 10 62199 male      57  28   More than high school 
    ## # ℹ 218 more rows

Now, we join the two cleaned tables to include all valid observations:

``` r
nhanes = merge(nhanes_covar_cleaned, nhanes_accel_cleaned, by = "seqn")
```

Produce a reader-friendly table for the number of men and women in each
education category:

``` r
nhanes_sex_tbl = 
  nhanes |>
  group_by(education, sex) |>
  summarize(num_people = n_distinct(seqn))|>
  pivot_wider(names_from = sex, values_from = num_people) |>
  arrange(education) |>
  knitr::kable(title = "Number of Men and Women in Each Education Category", 
               col.names = c("Education", "Female", "Male"))

nhanes_sex_tbl
```

| Education              | Female | Male |
|:-----------------------|-------:|-----:|
| High school equivalent |     23 |   35 |
| Less than high school  |     28 |   27 |
| More than high school  |     59 |   56 |

Next, create a visualization of the age distributions for men and women
in each education category:

``` r
ggplot(nhanes, aes(x = education, y = age, fill = sex)) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Pastel1", name = "Sex") + 
  labs(title = "Age Distribution by Gender and Education",
       x = "Education Level",
       y = "Age") +
  theme_minimal()
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-22-1.png)<!-- -->

Based on the table above, there are more female in the higher education
group, while fewer female in the high school equivalent background
compared to male.

The boxplot that displays the age distribution of participants across
different education levels.

Among those who participated in the NHANES study, the group with “high
school or equivalent” degree has the highest median age for females. The
group with “more than high school degree” has the lowest median age for
females.

Among those who participated in the NHANES study, the group with “less
than high school” degree has the highest median age for males. The group
with “more than high school degree” has the lowest median age for males.

Using the tidied dataset from above, aggregate across minutes to create
a total activity variable for each participant:

``` r
total_act = nhanes |>
  mutate(total_activity = rowSums(across(min1:min1440), na.rm = TRUE))
```

Make a 3-panel plot:

``` r
ggplot(total_act, aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = .5) +
  facet_wrap(~education) +
  geom_smooth() +
  labs(title = "Total Activity for Male vs Female", 
       x = "Age", 
       y = "Total Activity")
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-24-1.png)<!-- -->

For all groups of participants, the general trend of total activity time
versus age is decreasing, which makes sense because elder people tend to
do less exercise.

For “high school equivalent” and “more than high school” groups, male
generally have fewer total activity time across each age bins. Total
activity time plot for participants with “high school equivalent” degree
shows a “peak” of activity time at around age 40 for both genders. For
the other two groups, the “peak” is around at 60.

Lastly, we make a 24-hour activity time courses plot:

``` r
total_act_24hrs = 
  nhanes |>
  group_by(education, sex) |>
  summarise(across(starts_with("min"), ~ mean(.), .names = "mean_{.col}")) |>
  pivot_longer(
    cols = starts_with("mean_"), 
    names_to = "time", 
    values_to = "mean") |>
  mutate(time = substring(time, 9),
         time = as.numeric(time))
```

Make a 3-panel plot:

``` r
ggplot(total_act_24hrs, aes(x = time, y = mean, color = sex)) +
  geom_line() +
  facet_grid(. ~education) +
  labs(title = "24-Hour Activity by Education and Gender", 
       x = "Time (min)", 
       y = "Activity")
```

![](p8105_hw3_md4270_files/figure-gfm/unnamed-chunk-26-1.png)<!-- -->

All three plots show a surprisingly similar trends for 24-hour activity
time change. For the group with “less than high school” degree, there is
not much difference across male and female (two lines basically
overlap). For the other two, female tend to have a higher mean value of
activity time than male do.
